---
permalink: /
title: "Ping's Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
# üëã About Me

Hi! My name is **Ping Guo (ÈÉ≠Âπ≥)**. Currently, I am working at TikTok, focusing on the foundational training of large language models, particularly in the multilingual pretraining and CPT areas. I achieved my Ph.D. diploma at the [School of Cyberspace Security, University of Chinese Academy of Sciences](https://scs.ucas.ac.cn/index.php/zh-cn/), where I was advised by [Prof. Yue Hu](https://people.ucas.ac.cn/~0031884). Before that, I received my B.Eng. degree in Automation from the [School of Information Science and Engineering at Northeastern University](http://www.ise.neu.edu.cn/) in 2019.  


# ‚≠ê Research Highlights 

<div class="paper-container">
<div class="paper-image">
<img src="images/emmax.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">EMMA-X: An EM-like Multilingual Pre-training Algorithm for Cross-lingual Representation Learning</div>
<p class="paper-authors"><strong style="text-decoration-line: underline;">Ping Guo</strong>, Xiangpeng Wei, Yue Hu, Baosong Yang, Dayiheng Liu, Fei Huang, Jun Xie</p>
<p class="paper-venue">37th Conference on Neural Information Processing Systems (NeurIPS 2023) </p>
<p class="paper-links"><a href="https://dl.acm.org/doi/abs/10.5555/3666122.3666564">[Paper]</a> <a href="https://github.com/guopingiie/EMMA-X">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/mimir.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">Query in Your Tongue: Reinforce Large Language Models with Retrievers for Cross-lingual Search Generative Experience</div>
<p class="paper-authors"><strong style="text-decoration-line: underline;">Ping Guo</strong>, Yue Hu, Yanan Cao, Yubing Ren, Yunpeng Li, Heyan Huang</p>
<p class="paper-venue">WWW '24: Proceedings of the ACM Web Conference 2024 </p>
<p class="paper-links"><a href="https://dl.acm.org/doi/10.1145/3589334.3645701">[Paper]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/amsr.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">Steering Large Language Models for Cross-lingual Information Retrieval</div>
<p class="paper-authors"><strong style="text-decoration-line: underline;">Ping Guo</strong>, Yubing Ren, Yue Hu, Yanan Cao, Yunpeng Li, Heyan Huang</p>
<p class="paper-venue">SIGIR '24: Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval </p>
<p class="paper-links"><a href="https://dl.acm.org/doi/10.1145/3626772.3657819">[Paper]</a> </p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/riw.png" alt="LLM Watermarking Overview">
</div>
<div class="paper-text">
<div class="paper-title">Subtle Signatures, Strong Shields: Advancing Robust and Imperceptible Watermarking in Large Language Models</div>
<p class="paper-authors">Yubing Ren, <strong style="text-decoration-line: underline;">Ping Guo</strong>, Yanan Cao, Wei Ma</p>
<p class="paper-venue">Findings of the Association for Computational Linguistics: ACL 2024</p>
<p class="paper-links"><a href="https://aclanthology.org/2024.findings-acl.327/">[Paper]</a> <a href="https://github.com/Lilice-r/RIW">[Code]</a> </p>
</div>
</div>


<!-- # üî• News
- *2025.01*: üéâüéâ Two papers are accepted by [NAACL 2025](https://2025.naacl.org/).
- *2025.01*: üéâüéâ Three papers are accepted by [ICLR 2025](https://iclr.cc/).
- *2024.10*: üéâüéâ Excited to announce the our paper: [MarkLLM: An Open-Source Toolkit for LLM Watermarking](https://arxiv.org/pdf/2405.10051) is accepted by [EMNLP 2024 Demo Track](https://2024.emnlp.org/).
- *2024.09*: üéâ One paper about Retrieval-Augmented Large Language Models is accepted by [EMNLP 2024](https://2024.emnlp.org/).
- *2024.08*: üéâüéâ Excited to announce the our paper: "A Survey of Text Watermarking in the Era of Large Language Models" [Paper](https://arxiv.org/pdf/2312.07913) is accepted by [ACM Computing Surveys](https://dl.acm.org/journal/csur)!
- *2024.08*: Invited as a reviewer for [ICLR 2025](https://iclr.cc/).
- *2024.08*: üéâüéâ Excited to announce the updated version of our paper: "A Survey of Text Watermarking in the Era of Large Language Models" [Paper](https://arxiv.org/pdf/2312.07913)!
- *2024.05*: üéâüéâ One paper about Large Language Model Alignment is accepted by [ACL 2024](https://2024.aclweb.org/).
- *2024.05*: üéâüéâ Two papers about watermark for Large Language Models are accepted by [ACL 2024](https://2024.aclweb.org/).
- *2024.05*: üéâüéâ One paper about Document Relation Extraction is accepted by [Findings of ACL 2024](https://2024.aclweb.org/).
- *2024.04*: üéâüéâ Our tutorial proposal "Preventing and Detecting Misinformation Generated by Large Language Models" is accepted by SIGIR 2024. [SIGIR 2024](https://sigir-2024.github.io/).
- *2024.04*: Invited as a reviewer for [ACMMM 2024](https://2024.acmmm.org/).
- *2024.04*: Invited as a reviewer for [ACL ARR April](https://openreview.net/group?id=aclweb.org/ACL/ARR/2024/April).
- *2024.02*: Invited as a reviewer for [ACL ARR February](https://openreview.net/group?id=aclweb.org/ACL/ARR/2024/February).
- *2024.01*: üéâüéâ Two papers about watermark for Large Language Models are accepted by [ICLR 2024](https://iclr.cc/).

 -->



<!-- # üî¨ Research

* Preventing and Detecting Misinformation Generated by Large Language Models **<span style="color: #ff6666;">(SIGIR 2024 Tutorial)</span>** [[Home]](https://sigir24-llm-misinformation.github.io/) [[Paper]](https://dl.acm.org/doi/10.1145/3626772.3661377)[[Conference Page]](https://sigir-2024.github.io/attend_Tutorials.html#tut5) 1Ô∏è‚É£ 

**Watermark for Large Language Models**

*  An Unforgeable Publicly Verifiable Watermark for Large Language Models **<span style="color: #ff6666;">(ICLR 2024)</span>** [[Paper]](https://arxiv.org/pdf/2307.16230.pdf) [[Code]](https://github.com/THU-BPM/unforgeable_watermark) 1Ô∏è‚É£
*  A Semantic Invariant Robust Watermark for Large Language Models **<span style="color: #ff6666;">(ICLR 2024)</span>** [[Paper]](https://arxiv.org/pdf/2310.06356.pdf) [[Code]](https://github.com/THU-BPM/Robust_Watermark)1Ô∏è‚É£
*  A Survey of Text Watermarking in the Era of Large Language Models **<span style="color: #ff6666;">(ACM Computing Surveys)</span>** [[Paper]](https://arxiv.org/pdf/2312.07913.pdf)[[Êú∫Âô®‰πãÂøÉ]](https://mp.weixin.qq.com/s/U3ZzGsi3Yihueqr6MGRHfg) [[Twitter]](https://x.com/Aiwei_Liu_99/status/1821673541026099519) [[Home]](https://survey-text-watermark.github.io/)  1Ô∏è‚É£
*  Can Watermarked LLMs be Identified by Users via Crafted Prompts? **<span style="color: #ff6666;">(ICLR 2025)</span>** [[Paper]](https://arxiv.org/abs/2410.03168) 1Ô∏è‚É£
*  MarkLLM: An Open-Source Toolkit for LLM Watermarking **<span style="color: #ff6666;">(EMNLP 2024 Demo)</span>** [[Paper]](https://arxiv.org/pdf/2405.10051) [[Êú∫Âô®‰πãÂøÉ]](https://mp.weixin.qq.com/s/lx9ZNeHae4mo1J6_sFubfg) [[Code]](https://github.com/THU-BPM/MarkLLM)üí° 
* An Entropy-based Text Watermarking Detection Method **<span style="color: #ff6666;">(ACL 2024 Main)</span>** [[Paper]](https://arxiv.org/pdf/2403.13485.pdf) [[Code]](https://github.com/luyijian3/EWD)üí° 
* Cross-lingual Consistency for Text Watermark **<span style="color: #ff6666;">(ACL 2024 Main)</span>** [[Paper]](https://arxiv.org/pdf/2402.14007.pdf) [[Code]](https://github.com/zwhe99/X-SIR)üí°
* WaterSeeker: Pioneering Efficient Detection of Watermarked Segments in Large Documents **<span style="color: #ff6666;">(NAACL 2025 Findings)</span>** [[Paper]](https://arxiv.org/pdf/2409.05112) üí°


**Safety Alignment for Large Language Models**

* Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation **<span style="color: #ff6666;">(ACL 2024 Main)</span>** [[Paper]](https://arxiv.org/pdf/2402.11907.pdf) [[Apple Website]](https://machinelearning.apple.com/research/direct-large-language)1Ô∏è‚É£
* TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights **<span style="color: #ff6666;">(ICLR 2025)</span>** [[Paper]](https://arxiv.org/pdf/2410.04350v1) 1Ô∏è‚É£

**Adversarial Examples for Large Language Models**

* Character-level White-Box Adversarial Attacks against Transformers via Attachable Subwords Substitution **<span style="color: #ff6666;">(EMNLP 2022 Main)</span>** [[Paper]](https://aclanthology.org/2022.emnlp-main.522) [[Code]](https://github.com/THU-BPM/CWBA)1Ô∏è‚É£

**Semantic Parsing with Large Language Models**

* Semantic Enhanced Text-to-SQL Parsing via Iteratively Learning Schema Linking Graph **<span style="color: #ff6666;">(SIGKDD 2022)</span>**  [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3534678.3539294) [[Code]](https://github.com/THU-BPM/ISESL-SQL)1Ô∏è‚É£ 
* Exploring the Compositional Generalization in Context Dependent Text-to-SQL Parsing **<span style="color: #ff6666;">(ACL 2023 Findings)</span>** [[Paper]](https://aclanthology.org/2023.findings-acl.43.pdf) [[Code]](https://github.com/THU-BPM/CD-Text2SQL-CG)1Ô∏è‚É£
* A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability **<span style="color: #ff6666;">(Pre-print)</span>**  [[Paper]](https://arxiv.org/abs/2303.13547) [[Code]](https://github.com/THU-BPM/chatgpt-sql) 1Ô∏è‚É£

**Fact Checking with Large Language Models**

* CHEF: A Pilot Chinese Dataset for Evidence-Based Fact-Checking  **<span style="color: #ff6666;">(NAACL 2022)</span>**[[Paper]](https://arxiv.org/abs/2206.11863)  [[Code]](https://github.com/THU-BPM/CHEF)üí° 
  

**Retrieval-Augmented Large Language Models**

* Entropy-Based Decoding for Retrieval-Augmented Large Language Models **<span style="color: #ff6666;">(MINT@NeurIPS2024)</span>**[[Paper]](https://arxiv.org/pdf/2406.17519) üí° 
* Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities **<span style="color: #ff6666;">(EMNLP 2024 Findings)</span>**[[Paper]](https://arxiv.org/pdf/2406.11357) üí°  -->

<!-- **Information Extraction**

* GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks [[ACL 2023 Findings]](https://arxiv.org/abs/2305.16663) üèÖ 
* RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction [[EMNLP 2023]](https://aclanthology.org/2023.emnlp-main.316.pdf) üí° 
* Reading Broadly to Open Your Mind Improving Open Relation Extraction With Search Documents Under Self-Supervisions [[TKDE]](https://ieeexplore.ieee.org/abstract/document/10255305) üí°
* Entity-to-Text based Data Augmentation with Semantic Coherence and Entity Preserving for various NER Tasks [[ACL 2023 Findings]](https://aclanthology.org/2023.findings-acl.578.pdf) üí°
* Guassian Prior Reinforcement Learning for Nested Named Entity Recognition [[ICASSP 2023]](https://ieeexplore.ieee.org/abstract/document/10097163/) üí° -->


<!-- ---

1Ô∏è‚É£: Leading contribution (First Author)
üí°: Insightful contribution

---
   -->

# üìû Contact

- üìß **Email**:
  -  guoping.114@bytedance.com
  -  gp826923024@gmail.com
- üí¨ **Wechat**:
  - PiTooYoung


# üéì Education

<div style="display: flex; margin-bottom: 2em; align-items: center;">
    <div style="margin-right: 2em;">
        <img src="images/cas_logo.png" alt="Chinese Academy of Sciences Logo" style="width: 80px; height: auto;">
    </div>
    <div>
        <div style="font-weight: bold;">University of Chinese Academy of Sciences, China</div>
        <div style="font-style: italic;">Ph.D. in Computer Technology</div>
        <div>Sept. 2019 - June 2024 </div>
    </div>
</div>

<div style="display: flex; margin-bottom: 2em; align-items: center;">
    <div style="margin-right: 2em;">
        <img src="images/neu_logo.png" alt="Northeastern University Logo" style="width: 80px; height: auto;">
    </div>
    <div>
        <div style="font-weight: bold;">Northeastern University, China</div>
        <div style="font-style: italic;">B.E. in Electrical Engineering</div>
        <div>Sept. 2015 - June 2019</div>
    </div>
</div>

<p align="center" style="padding-top: 40px;">
<a href="https://clustrmaps.com/site/1c55y"  title="Visit"><img src="//www.clustrmaps.com/map_v2.png?d=PEXVjQ9GhNNd4SArp_aOmAF_PL1vH3DTErVjd04eKeE&cl=ffffff" /></a>
</p>
<p align="center" style="padding-top: 100px;"> 
</p>


<style>
.paper-container {
    display: flex;
    gap: 20px;
    margin: 30px 0;
    padding: 15px;
    border-radius: 8px;
    background: #fff;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

hr {
    margin: 10px 0;
    height: 1px;
    background-color: #ddd;
    border: none;
}

.paper-image {
    flex: 0 0 300px;
    min-width: 0;
}

.paper-image img {
    width: 100%;
    height: auto;
    border-radius: 4px;
    border: 1px solid #eee;
}

.paper-text {
    flex: 1;
    min-width: 0;
}

.spotlight-badge {
    display: inline-block;
    background-color: #FFD700;
    color: #000;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 13px;
    font-weight: bold;
    margin-left: 8px;
    vertical-align: middle;
    font-family: "Microsoft YaHei";
}


.paper-title {
  font-family: "Microsoft YaHei",
  font-weight: 2000;
  -webkit-text-stroke: 0.9px black;  /* Ê∑ªÂä†ÊèèËæπÊïàÊûú‰ΩøÊñáÂ≠óÁúãËµ∑Êù•Êõ¥Á≤ó */
  font-size: 18px;
  margin: 0 0 8px 0;
  color: #000;
}

.paper-authors {
  font-family: "Microsoft YaHei",
   margin: 2px 0;
    font-size: 14.5px;         /* Ë∞ÉÂ∞è‰ΩúËÄÖÂ≠ó‰Ωì */
    color: rgba(0,0,0,0.9);    /* Êõ¥Ëá™ÁÑ∂ÁöÑÁÅ∞Ëâ≤ */
    font-weight: 400;          /* Êõ¥ÁªÜÁöÑÂ≠óÈáç */
}

.paper-venue {
   font-family: "Microsoft YaHei",
    color: #d83931;
    font-style: italic;
    font-size: 0.95em;
    margin: 3px 0;
}

.paper-links {
  font-family: "Microsoft YaHei",
    font-size: 0.9em;
    margin: 3px 0;
}

.paper-links a {
    margin-right: 10px;
    color: #4A90E2;
    text-decoration: none;
    transition: color 0.2s ease;
}

.paper-links a:hover {
    color: #357ABD;
}

@media (max-width: 768px) {
    .paper-container {
        flex-direction: column;
    }
    
    .paper-image {
        flex: 0 0 auto;
        width: 100%;
    }
}
</style>
